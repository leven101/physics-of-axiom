\documentclass[11pt]{article}
\usepackage{fullpage}
\usepackage{hyperref}
\usepackage{comment}
\title{Theory of Axiom/Definition}
\author{Abby Levenberg, PhD}
\begin{document}
\maketitle
\begin{abstract}
 This is a logical treatise of definition and an attempt to satisfy a physical construction of axiom. We show that now there is no satisfactory formulation for a definition of axiom and that this follows because of the incompleteness theorem. We then aim to construct a simple functional interpretation of this well known problem. We show a connection between the proposed functional definition of axiom and statistical inference frameworks and also the principle of quantum entanglement. 
\end{abstract}

\include{preamble}

\section{Theory}
Axiom has a geometric physical formulation that is both measurable, discoverable and continuous.  
We can write $\delta(f(x))$, where $f(x)$ is any function derived from an underlying axiom, as the space where the function works and can be defined using notation encoded by $\delta$. 
We also write $\not\delta(f(x))$ to denote the space where a given function $f(x)$ is undefinable.
Then the construction of the underlying axioms governing the function $f(x)$ can be approximated by a continuous representation using the formula $$\frac{\lim_{f(x) \rightarrow \infty} \delta(f(x))}{\lim_{f(x) \rightarrow 0} \not \delta(f(x))} $$ 

\subsection{Supporting Evidence}
The defense of the theory is presented as a the list of logical thoughts leading up to the conclusion. 

\begin{itemize}
\item Let us formalize a theoretical and logical TOE with the definition of the space of all possible functions. We will call this equivalence \emph{definition of the theory of everything} (DTOE). 
\item Let the DTOE be equivalent to the definition of nothing plus the definition of all the parts of everything that is "not nothing". So $DTOE := definition(nothing) + definition(everything else)$. This at least separates the definition of zero, or nothing, from the rest of everything and allows us to play with logically independent components of DTOE algebraically.

\begin{itemize}
\item $definition(nothing) = 0$ is well defined as the set that can contain nothing else but itself.  
\item Of course the $definition(everything else)$ is back to the original problem. 
\item However by simple logic we know that $\neg definition(nothing) = definition(something)$ is one element in the set of $definition(everything else)$. We can write $definition(everything else) = \sum_{\forall\exists} \neg definition(nothing)$,  
\end{itemize}

\item Recap: DTOE :=  definition of all possible functions := $def(nothing) + \sum_{\forall\exists} \neg def(nothing)$. 
\item Now algebraically the difference between everything and nothing is only in this definition of something.  $def(everything) = def(nothing) + def(everything else) => def(everything) - def(nothing) := \sum_{\forall\exists} \neg def(nothing)$. 
\item This holds logically as well. For both nothing and everything the following statements are true
\begin{itemize}
\item can not add/subtract/divide/multiple anything
\item can not create any subpart that is not already present
\item You can not observe/define any subset of zero. However you can observe/define some subset of everything. 
\end{itemize}

\item Assumption: Existence grows in complexity from simple to more complex. I.E., chemical elements, cells, etc.
 \item Given assumption above then a priori it is impossible for there ever to have been nothing only. 
 \begin{itemize}
\item As a counter proof, assume at some point in time there was nothing in the universe. In words the universe was wholly relative to itself. 
\item Concerning everything else that exists now in the universe, then in the absence of a preexisting external force, how can something come from nothing? 
\item Logically it is impossible. 
\item Which means that there was always something that existed that was not nothing by definition.
\item But what is that definition? Back to the original problem again. 
\end{itemize}

\item Definition of any mathematical construction always falls back on axioms. 
\item For example, the ordinals are the lowest level mathematical constructions and are considered a priori true. Hence their existence and definition is considered an axiom. 
\item The integers are recursively defined. Most widely accepted working definition is the ZF axiomatic definition of the "axiom of infinity" which corresponds to the von Neumann ordinals.
 
\begin{itemize}
\item ZF axiomatic definition of integers is incrementally recursive beginning with the empty set $0 = \{\}$ and $n + 1 = n \cup \{n\}$. So the first few well ordered integers are formulated as
$$ 0 = \{\} = \emptyset $$
$$ 1 = \{0\} = \{\emptyset\}$$
$$ 2 = \{0,1\} = \{\emptyset, \{\emptyset\}\}$$
$$ 3 = \{0,1,2\} = \{\emptyset, \{\emptyset\}, \{\emptyset, \{\emptyset\}\}\}$$
\end{itemize}

\item  However a closer look at this accepted formulation of the definition of the axiom contains a logical inconsistency and circular reasoning with a self-contained dependency that is never satisfied. Observe that
\begin{itemize}
\item The number $0$ is defined using $1$ set. So the axiomatic definition of $0$ is dependent on the a priori existence of the number $1$ which in turn is wholly dependent on the definition of $0$. In isolation this could be principled so long as the number $1$ is defined consistently.
\item However the number $1$ is defined using $2$ sets. This means the definition of the number $0$, which is defined as the a priori existence of $1$, is dependent on the definition of the number $2$ a priori. Again this is principled so long we can define the number $2$.
\item But the definition of the number $2$ requires us to use $3$ sets again forcing the definition of the number $0$ to be dependent on the definition of the number $3$. 
\item By induction each ordinal $n$ is defined dependent on the successor ordinal begin defined. This process repeats and would be principled except that by this very axiom of infinity if we continue to recurse along this process for long enough we eventually arrive at the (countably) infinite. 
\item Then $\infty + 1 = \infty$ and $\infty - 1 = \infty$. 
\item This means that the definition of $0$ is never satisfied since since it depends on the definition of each successor until $\infty$ where no incremental definition is possible. 
 \item This immediately begs the question at which point along the well ordered integer line does the definition of the ordinals fail? 
 \item Where is the point that the axiom that numbers exist as incrementally recursive functions well defined and where does the axiom fail? 
 \item Where does infinity begin and the definition of the ordinal numbers fail? 
 \end{itemize}
 
 \item So the definition of the numbers --- most basic axiom of mathematics --- is circular and self referential. (This implies this ZF axiomatic definition is invalid due to Gödel's incompleteness theorem.)
  \item By construction axiom is universally true a priori but given the logical inconsistency above we know there is a point where the definition of the axiom is invalid. 
 \item But by experimental science we know that functions work based off of these axiomatic definitions for some measurable spacetime. So it is only the definition of the axiom that fails, and that only in the limit of the definition. 
 \item In plain English we could say there is a measurable space where a axiom/definition holds but also a definite space where the definition does not hold.  
\item This begs a new logical construction of axiom/definition as a function which can be described as the limit of the space where the definition holds \emph{pressed against} the limit of the space of where the definition does not hold.  
\item To this end we construct a new operator, $\delta(f(x))$ which we use to denote the space of valid definition of a given function $f(x)$ up to the current point $x$ and use $\not \delta(f(x))$ to denote the space where the definition of $f(x)$ does not hold for $x$. 
\item We can then formulate this new point function for the definition of axiom/definition. 
\begin{itemize}
\item The limit of the definition of the axiom $f(x)$ to the point where the definition of the axiom holds. Here we use the infinity symbol $\infty$ to denote the point where the definition become invalid. $$\lim_{f(x) \rightarrow \infty} \delta (f(x))$$
\item Conversely taking the limit of the space where the definition of the axiom does \emph{not} hold. Here we use $0$ to denote the point where the definition begins. $$\lim_{f(x) \rightarrow 0} \not \delta (f(x))$$
\item Combining these points together to find the point function definition of the axiom. (For now) we denote the combination using the $\cup$ operator. 
$$ \lim_{f(x) \rightarrow \infty} \delta(f(x)) \cup \lim_{f(x) \rightarrow 0} \not \delta(f(x)) $$
\item To locate this point in spacetime requires a normalization of the space of all functions that are not $f(x)$. This gives the full expression as
$$ \frac{\lim_{f(x) \rightarrow \infty} \delta(f(x)) \cup \lim_{f(x) \rightarrow 0} \not \delta(f(x))}{\forall_{\{i | f(i) \neq f(x)\}}\lim_{f(i) \rightarrow \infty} \delta(f(i)) \cup \lim_{f(i) \rightarrow 0} \not\delta(f(i))} $$
\item Of course this is massively intractable to compute. However a quick simplification is to note that the space of the "not definition" $\not \delta (f(x))$ implicitly approximates that space of all other functions that are not equal to $f(x)$. Hence we can ignore the normalization denominator and use only the numerator for computational purposes.
\item This gives a final simplified continuous definition of axiom as $$\frac{\lim_{f(x) \rightarrow \infty} \delta(f(x))}{\lim_{f(x) \rightarrow 0} \not \delta(f(x))} $$
\end{itemize}
\end{itemize}


\section{Applications and Corollaries}
\subsection{Framework for Statistical Inference}
Given a definition of a target with an unknown corresponding function we can search or sample the space around the limit of the known definition. Starting with a random or best-guess function definition every sample of the unknown space around the point of the limit adds to knowledge surrounding the space of the of the current best-guess definition. 
Here we can employ a direct application of binary sampling, i.e., does the new sample improve the definition (did we sample a part of the definition) or not (sampling not part of the target definition). 

Example: we know there is a point when a stock changes direction but we don't know the functional definition. Given a best-guess definition of the function at the current time, we sample new potential definitions around the point of the current definition and temporarily expand the current functional definition. We can then backtest and see if the current function is more accurately defined given the data.   

\subsection{Quantum Entanglement Approximation and Application via the Heisenberg principle}
This function has no single point numerical solution. For example, solving the function for the definition of one means we use axiom of infinity at the numerator. The additive definition of the ordinals is principled until it is met by the the point where the definition no longer holds, i.e., the "beginning" of infinity of the number line. This isn't a real point so is described by the denominator and can be treated as itself a continuous function. However by the functions definition we have no definition for the negative space. So in theory how can we sample against it? \footnote{In practice we can sample against an observable universe comprised of hard data points.} Since we have no principled way to understand the space where the definition of the numbers is not defined we can not compute this to any point even in theory. 

Instead the discovery of the solution should be treated as obeying the Heisenberg principle. In this context the solution is of the definition can either be observed at the point $f(x)$ or the velocity of the direction of the limit can measured but not both at the same time. 

This could be a stretch but it may be possible to realign our understanding of entanglement strictly within the domain of application of entanglement to computing devices. If we treat the current point of definition of the function as an encoding of an entangled point in spacetime. Then we can observe either velocity or positional statistics of the entangled function and take logical action according to the results. These instructions could be parallelized between hardware via customized circuits and controlling software. 

\subsection{Energy Production}
By building a silicon chip that attempts to compute the definition we can possibly generate an energy signature that we could grow arbitrarily via transformers. The chip would be in the form of "teeth" nodes where each tooth represents an integer definition. The process would be to continually attempt to find the definition that satisfies the completeness of the integer definition according to the ZF axioms as described above. To do this the software would mirror the hardware so when the memory reached a maximum integer count for the chip the software would randomly jump to another tooth on the chip and in doing so would generate the energy signature that we could capture. 


\end{document}






















